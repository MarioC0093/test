[
  {
    "objectID": "tema_02/tema_02_1_2_cohortes_y_casos_control.html#estudios-cohorte",
    "href": "tema_02/tema_02_1_2_cohortes_y_casos_control.html#estudios-cohorte",
    "title": "1.2 Estudios de cohorte y casos-control ✓",
    "section": "Estudios cohorte",
    "text": "Estudios cohorte\nSupongamos que realizamos un experimento con resultados {éxito, fracaso} y sea \\(\\text{p = p(éxito)}\\). Repetimos el experimento n veces en condiciones independientes. Sea \\(X \\sim \\text{\"número de éxitos en n pruebas\"}\\) bajo el modelo teórico B(n,p). Sea \\(\\hat p\\) = número de éxitos observados en el total de muestras = \\(\\frac{x}{n}\\)\n\\(N\\) = nº de sujetos seleccionados aleatoriamente de la población\\(n_{{D}}\\) = nº de sujetos con la enfermedad de los N seleccionado\\(n_{\\overline{D}}\\) = nº de sujetos sin la enfermedad de los N seleccionados\\(n^+\\) = nº de sujetos que han dado positivo en el test de los N\\(n^-\\) = nº de sujetos que han dado negativo en el test de los N\n\n\n\n\\[\n\\scriptsize\n\\begin{array}{cc|c|c|c}\n& & \\text{prueba +} & \\text{prueba -} & \\\\\n& & D = 0 & D = 1 & \\\\\n\\hline\n\\text{persona enferma} & \\text{Y = 0} & n_{\\overline{D}}^{-} & n_{D}^{-} & n^{-} \\\\\n\\text{persona sana} & \\text{Y = 1} & n_{\\overline{D}}^{+} & n_{D}^{+} & n^{+} \\\\\n\\hline\n&& n_{\\overline{D}} & n_{D}\n\\end{array}\n\\]\n\n\n\\[\n\\scriptsize\n\\begin{array}{c|c|c|c}\n& \\text{persona enferma} & \\text{persona sana} & \\\\\n& \\text{Y = 0} & \\text{Y = 1} & \\\\\n\\hline\n\\text{prueba +} \\ D = 0 & n_{\\overline{D}}^{-} & n_{\\overline{D}}^{+} & n_{\\overline{D}} \\\\\n\\text{prueba -} \\ D = 1 & n_{D}^{-} & n_{D}^{+} & n_{D} \\\\\n\\hline\n& n^{-} & n^{+}\n\\end{array}\n\\]\n\n\n\n\nDetrás de cada una de las probabilidades hay una distribucion binomial. Los intervalos de confianza de cada proporción binomial \\(\\hat p\\) se puede calcular a través de:\n\n\nIntervalos de confianza exactos \\(\\Rightarrow\\) Intervalo de Clopper-Pearson (se basa en la función de distribución binomial acumulativa invertida)\n\n\\[\n\\text{IC}_{1-\\alpha} = \\left[\n\\frac{x}{x + (n - x + 1)F_{1-\\alpha/2, 2x, 2(n-x+1)}}, \\,\n\\frac{(x+1)F_{\\alpha/2, 2(x+1), 2(n-x)}}{(n-x) + (x+1)F_{\\alpha/2, 2(x+1), 2(n-x)}}\n\\right]\n\\]\n\n\nLa distribución binomial o métodos asintóticos \\(\\Rightarrow\\) Cuando \\(n\\) es grande, las observaciones son independientes y \\(\\hat p\\) no es cercano a 0 o 1 (eventos raros)\n\n\\[\n\\left( \\frac{x}{m} \\pm z_{\\alpha/2} \\sqrt{\\frac{ x\\left(1 - \\frac{x}{m}\\right)}{m}} \\right)\n\\]\n\nEstimadores (I)\n\nPara estimar la probabilidad de verderos negativos \\(\\widehat{Se}\\) se usa la v.a.:\n\\[\nX \\sim \\text{\"número de negativos en el grupo de enfermos\"} \\sim Bin(n_{D}^{+}, Se) = Bin(n_{D}^{+}, n_D)\n\\]\nPara estimar la probabilidad de falsos positivos \\(\\widehat{(1-Sp)}\\) se usa la v.a.:\n\\[\nX \\sim \\text{\"número de enfermos en el grupo de sanos\"} \\sim Bin(n_{\\overline{D}}^{+}, (1-Sp)) = Bin(n_{\\overline{D}}^{+}, n_{\\overline{D}})\n\\]\nPara estimar el valor predictivo \\(\\widehat{PPV}\\) se usa la v.a.:\n\\[\nX \\sim \\text{\"número de individuos enfermos en sujetos con test postitivo.\"} \\sim Bin(n_{\\overline{D}}, (1-Sp)) TERMINAR\n\\]\n\\[\nX \\sim Bin(n^+, ppv), \\quad \\quad x =  n_{\\overline{D}}^+\n\\]\nPara estimar el valor predictivo \\(\\widehat{NPV}\\) se usa la v.a.:\n\\[\nX \\sim \\text{número de individuos enferos en los que tienen test postitivo} ~ Bin(n^-, npv), \\quad \\quad x =  n_{\\overline{D}}^- TERMINAR\n\\]\n\nEjemplo del intervalo de confianza exacto para la sensibilidad.\n\\[\nIC_{1-\\alpha} (\\widehat{\\text{Se}}) =\n\\left(\n\\frac{1}{1 + \\frac{n_D^+ F_{2n_D^+ , 2(n_D - n_D^+ + 1); 1-\\alpha/2}}{n_D^+ - n_D^+ + 1}} , \\\n\\frac{1}{1 + \\frac{(n_D^+ + 1) F_{2(n_D^+ + 1), 2(n_D - n_D^+); \\alpha/2}}{n_D - n_D^+}}\n\\right)\n\\]\nEjemplo del intervalo de confianza por el método asintótico para la sensibilidad.\n\\[\nIC_{1-\\alpha} (\\widehat{Se}) =\n\\left(\n\\frac{n^+_D}{n_D} - z_{\\alpha/2} \\cdot \\sqrt{\\frac{1}{n_D} \\cdot \\frac{n^+_D \\left( n_D - n^+_D \\right)}{n_D}}, \\;\n\\frac{n^+_D}{n_D} + z_{\\alpha/2} \\cdot \\sqrt{\\frac{1}{n_D} \\cdot \\frac{n^+_D \\left( n_D - n^+_D \\right)}{n_D}}\n\\right)\n\\]\nEjemplo 2.2.\nEl objetivo es determinar qué constituye un éxito y en qué subgrupo estamos evaluando la cantidad de éxitos.\nEn el cálculo de estimaciones e IC, en cada IC que genero cometo un error y a mayor númeor de estimaciones e IC el error total de mi proyecto aumenta o la precision total disminuye.\n- Probabiidad de que la sensibilidad esté dentro de mi intervalo, 0.9.\n- Probabiidad de que la especificidad esté dentro de mi intervalo, 0.9.\n- Probabiidad de que la sensibilidad esté dentro de mi intervalo y de que la especificidad esté dentro de mi intervalo, 0.9*0.9. (es un cálculo teórico para entenderlo)\nLos estimadores de la probabilidades de clasificación son independientes. Esto nos motiva a buscar una region de confianza de tal forma que ambas estimaciones estén dentro de esa región con una probabilidad del 0.9.\nRegión de confianza para (\\(\\widehat{Se}, (\\widehat{1-Sp})\\))\n\nConfianza bidimensional \\(1-\\alpha = \\text{\"prob de caer en el IC * prob de caer en el otro IC\"} = \\beta^2 : \\beta = \\sqrt{1-\\alpha}\\).\n\nLa RC es una zona de confort en dos dimensiones. En caso de trabajar en dos dimensiones separadas consigo una confianza menor.\nEjemplo 2.2. (cont.)\nLos siguientes datos corresponden a un estudio cohorte realizado en el que se tenían 1465 hombres con posible enfermedad coronaria para los que se tiene el resultado de una prueba diagnóstica de esfuerzo (EST). La determinación de la enfermedad se realiza con arteriografía, la medida gold standard. Los datos obtenidos son los siguientes:\n\nlibrary(dplyr)\n\ndf &lt;- data.frame(col1 = c(327, 115),\n                 col2 = c(208, 815)\n)\ncolnames(df) &lt;- c(\"D=0\", \"D=1\")\nrownames(df) &lt;- c(\"Y=0\", \"Y=1\")\n\ndf_extended &lt;- rbind(df, \"Total\" = colSums(df))\ndf_extended &lt;- df_extended |&gt; mutate(\"Total\" = rowSums(df_extended))\ndf_extended\n##       D=0  D=1 Total\n## Y=0   327  208   535\n## Y=1   115  815   930\n## Total 442 1023  1465\n\nEn medcalc por defecto te calcula la asitótica (independientemente del tamaño que tengas). (para estudio de cohortes no hace falta indicarle la prevalencia porque da igual en este caso)\n\\(\\widehat{PPV}\\), estimo los casos positivos: 930 + cuántos lo son de verdad: 815 = \\(\\frac{815}{930}\\)\n\\(\\widehat{NPV}\\), casos negativos: 327 + cuántos lo son de verdad: 535 = \\(\\frac{327}{535}\\), un resultado positivo en la prueba estaría asociado a detectar un 87,63% de los casos\n\nsource(\"calculo_estimadores_pruebas_diagnosticas.R\")\n\n\nn_D &lt;- 1023\nn_D_pos &lt;- 815\nn_D_neg &lt;- 208\nn_noD &lt;- 442\nn_noD_pos &lt;- 115\nn_noD_neg &lt;- 327\nn_pos &lt;- n_D_pos + n_noD_pos\nn_neg &lt;- n_D_neg + n_noD_neg\n\n\nlibrary(tibble)\ncalculo_estimadores(n_D, n_D_pos, n_D_neg, n_noD, n_noD_pos, n_noD_neg, n_pos, n_neg, tipo_estudio = \"cohorte\") |&gt; as.data.frame() |&gt; rownames_to_column(var = \"rownames\") %&gt;% filter(rownames %in% c('Se', 'Sp', 'Uno_menos_Sp', 'PPV', 'NPV'))\n##       rownames   Puntual  IC.lower  IC.upper\n## 1           Se 0.7966764 0.7720135 0.8213394\n## 2           Sp 0.7398190 0.6989177 0.7807203\n## 3 Uno_menos_Sp 0.2601810 0.2192797 0.3010823\n## 4          PPV 0.8763441 0.8551872 0.8975010\n## 5          NPV 0.6112150 0.5699080 0.6525219\n\nUn resultado positivo en la prueba estaría asociado a detectar un 87,63% de los casos.\nEstimamos que al 79,67 % de los enfermos se les detectará la enfermedad mediante la prueba de esfuerzo. Estimamos que un 26,02 % de los sanos también se les diagnosticará como enfermos.\nRegión de confianza rectangular: \\(\\displaylines{IC_{95} (\\widehat{1-Sp}, \\widehat{Se}) = (0.2193, 0.3011) x (0.772, 0.821) : \\\\ (1−\\alpha^{*}) * (1−\\alpha^{*}) = (1−\\alpha) \\Rightarrow (1−\\alpha^{*}) = \\sqrt{1−\\alpha} = \\sqrt{0.95} = 0.9747}\\)\nEstimadores (II) - DLR\nComparación de casos positivos dentro del grupo de enfermos y casos positivos dentro del grupo de sanos \\(\\Rightarrow\\) En funcion del cociente se puede decididr cuál es más verosímil.\nSe estiman las razones de verosimilitud a través de las estimaciones de las probabilidades de clasificaciones.\n\n\n\n\\(\\widehat{DLR^+} = \\frac{\\widehat{Se}}{\\widehat{1-Sp}} = \\frac{{\\frac{n_{D}^{+}}{n_D}}}{\\frac{n_{\\overline{D}}^{+}}{n_{\\overline{D}}}}\\)\n\n\n\\(\\widehat{DLR^-} = \\frac{\\widehat{1-Se}}{\\widehat{Sp}} = \\frac{{\\frac{n_{D}^{-}}{n_D}}}{\\frac{n_{\\overline{D}}^{-}}{n_{\\overline{D}}}}\\)\n\n\n\nIC para las razones de verosimilutes\nLos intervalos de confianza de cada razón de verosimilitud estimada se determinan a partir del resultado asintótico.\nPasamos los DLR a escala logarítmica y separamos las componentes sensibilidad y especificidad. Trabajamos con el método delta.\n\\[\n\\left( \\log DLR^{+}, \\log DLR^{-} \\right) \\approx \\mathcal{N} \\left( \\left( \\log DLR^{+}, \\log DLR^{-} \\right);\n\\begin{pmatrix}\n\\frac{1 - Se}{n_D Se} + \\frac{Sp}{n_D (1 - Sp)} & - \\left( \\frac{1}{n_D} + \\frac{1}{n_D} \\right) \\\\\n\\left( \\frac{1}{n_D} + \\frac{1}{n_D} \\right) & \\frac{Se}{n_D (1 - Se)} + \\frac{1 - Sp}{n_D Sp}\n\\end{pmatrix}\n\\right)\n\\]\nEjemplo.\nDado el \\(IC(log(\\widehat{DLR^+})) = (-0.6, 2) : e^-0.6 &lt; \\widehat{DLR+} &lt; e^2\\). Se obtiene el \\(IC(\\widehat{DLR^+}) = (e^{-0.6}, e^2) = (0.55, 0.79)\\)\n“Las dos razones de verosimilitud no son independientes sino que cuando trabajamos con sus logaritmos tienen un comportamiento normal bidimensional. La covarianza negativa nos indica que una razón aunmenta la otra disminuye.”\n\nlibrary(MASS)\nlibrary(ggplot2)\n\n# Definimos la media y la matriz de covarianza\nmedia &lt;- c(0, 0)\ncovarianza &lt;- matrix(c(1, 0.5, 0.5, 1), nrow = 2)\n\n# Generamos los puntos con una distribución normal multivariada\ndatos &lt;- mvrnorm(n = 1000, mu = media, Sigma = covarianza)\ndatos &lt;- as.data.frame(datos)\ncolnames(datos) &lt;- c(\"X\", \"Y\")\n\nlibrary(plot3D)\nx &lt;- seq(-3, 3, length = 50)\ny &lt;- seq(-3, 3, length = 50)\nz &lt;- outer(x, y, function(x, y) mclust::dmvnorm(cbind(x, y), mean = media, sigma = covarianza))\npersp3D(x, y, z, theta = 30, phi = 20, expand = 0.6, col = \"lightblue\", main = \"Distribución Gaussiana Bidimensional\")\nmtext(\"Esto lo hago porque me aburro\", side = 3, line = 0.5, cex = 0.8)  # side = 3 coloca el texto arriba, line ajusta la distancia\n\n\n\n\nEjemplo 2.2. (cont. 21)\n\ncalculo_estimadores(n_D, n_D_pos, n_D_neg, n_noD, n_noD_pos, n_noD_neg, n_pos, n_neg, tipo_estudio = \"cohorte\") |&gt; as.data.frame() |&gt; rownames_to_column(var = \"rownames\") %&gt;% filter(rownames %in% c('DLR_pos', 'DLR_neg'))\n\n  rownames   Puntual  IC.lower  IC.upper\n1  DLR_pos 3.0620086 2.6086910 3.5941001\n2  DLR_neg 0.2748288 0.2405299 0.3140186\n\n\n\\(DLR^{+}\\): un resultado positivo es 3 veces más creíble en el grupo de enfermos que en el grupo de sanos\n\\(DLR^{-}\\): comparamos negativos en el grupo de sanos y en el grupo de enfermos. En el grupo de sanos deben ser pocos, por que lo que \\(DLR^{+}&lt;&lt;&lt;1\\). Para facilitar la comparativa se le suele dar la vuelta (al parecer es más fácil interpretar un 2 que un 0.5)\nEn el 95 % de las muestras es entre 2.6 y 3.5 veces más creíble un resultado positivo en el grupo de los enfermos que en los sanos.\nEl test de esfuerzo da positivo tres veces más en los enfermos que en sanos. Es tres veces más versosímil encontrar un positivo en la prueba de esfuerzo en un individuo enfermo que en un individio sano.\nCuando tenemos un resultado negativo en la prueba es 3.7 (1/0.2748) más verosímil un negativo en un individuo sano que en un individuo enfermo."
  },
  {
    "objectID": "tema_02/tema_02_1_2_cohortes_y_casos_control.html#estudios-caso-control",
    "href": "tema_02/tema_02_1_2_cohortes_y_casos_control.html#estudios-caso-control",
    "title": "1.2 Estudios de cohorte y casos-control ✓",
    "section": "Estudios caso control",
    "text": "Estudios caso control\nEl número de sujetos enfermos seleccionados y el de sujetos sanos seleccionados son predeterminados.\nEsta situación equilibrada no suele ser representativa de la realidad. La frecuencia relativa de sujetos enfermos es normalmente mucho mayor que en la población, al menos cuando la prevalencia es relativamente baja.\nLa prevalencia muestral no representativa de la prevalenciapoblacional no afecta a las estimaciones de sensibilidada, especificidad ni a las razones. Pero sí afectaa los valores predictivos.\nTrabajamos suponiendo que tenemos una estimación para la prevalencia real.\nEn estudios de caso-control la prevalencia de la población no se conserva en la muestra (los sujetos se elige en función de si tienen o no la enfermedad). En los estudios de cohortes ese problema no existe ya que se ha buscado un grupo de individuos que se someten a un riesgo y se espera a ver si tenían o no la enfermedad.\nDefinimos los valores predictivos en función de la prevalencia. Con el teorema de Bayes se expresan los valores predictivos en función de la sensibilidad y la especificidad.\n\\[\n\\scriptsize\n\\begin{aligned} PPV &= P(D=1 | Y=1) \\\\ &= \\frac{p(D=1 \\cap Y=1)}{p(Y=1)} \\\\ &= \\frac{p(Y=1 | D=1) · p(D=1)} {p(Y=1 | D=1) · p(D=1) + p(Y=1 | D=0) · p(D=0)} \\\\ &= \\frac{\\rho * Se}{\\rho * Se + (1-\\rho)(1-Sp)} \\end{aligned}\n\\begin{aligned} NPV &= P(D=0 | Y=0) \\\\ &= \\frac{p(D=0 \\cap Y=0)}{p(Y=0)} \\\\ &= \\frac{p(Y=0 | D=0) · p(D=0)} {p(Y=0 | D=0) · p(D=0) + p(Y=0 | D=1) · p(D=1)} \\\\ &= \\frac{(1-\\rho) · Sp}{(1-\\rho) · Sp + \\rho · (1-Sp)} \\end{aligned}\n\\]\n\\[\\hat{PPV} = \\frac{\\rho * \\hat{Se}}{\\rho * \\hat{Se} + (1-\\rho)(1-\\hat{Sp})} \\quad \\quad \\quad \\hat{NPV} = \\frac{(1-\\rho) · \\hat{Sp}}{(1-\\rho) · \\hat{Sp} + \\rho · (1-\\hat{Sp})}\\]\nSupongamos que desconocemos el valor exacto de la prevalencia:\n\nSi la prevalencia es máxima, \\(\\text{si }\\rho=1 \\Rightarrow PPV = 1 \\text{ y } NPV = 0\\).\nSi la prevalencia es mínima, \\(\\text{si }\\rho=0 \\Rightarrow PPV = 0 \\text{ y } NPV = 1\\).\n\n\n\n\n\n\n\nDefinimos los IC valores predictivos en función de las DLR.\n\\[\\scriptsize \\frac{PPV}{1-PPV} = DLR^+ (\\frac{\\rho}{1-\\rho}) \\Rightarrow ln(\\frac{PPV}{1-PPV}) = ln(DLR^+) + ln(\\frac{\\rho}{1-\\rho}) = ln(DLR^+) + logit(\\rho) = ln(DLR^+) + H\\]\n\n\\(\\begin{aligned} \\text{Sea } IC\\left(\\ln\\left(\\widehat{DLR^-}\\right)\\right) = (A, B) &\\Rightarrow A &lt; ln(\\widehat{DLR^-}) &lt; B \\\\ &\\Rightarrow -B &lt; -ln(\\widehat{DLR^-}) &lt; -A \\\\ &\\Rightarrow - H - B &lt; logit(NPV) &lt; - H - A \\\\ &\\Rightarrow - (H + B) &lt; logit(NPV) &lt; - (H + A) \\\\ &\\Rightarrow - (H + B) &lt; ln(\\frac{NPV}{1-NPV}) &lt; - (H + A) \\\\ &\\Rightarrow e^{- (H-B)} &lt; \\frac{NPV}{1-NPV} &lt; e^{- (H+A)} \\\\ &\\Rightarrow e^{- (H-B)} * (1-NPV) &lt; NPV &lt; e^{- (H+A)} * (1-NPV) \\\\ &\\Rightarrow \\text{Como } \\widehat{ppv} &gt; 0, exp^{b+H} &gt; exp^{a+H}(1-\\widehat{ppv}) &gt; \\frac{exp^{b+H}}{1+exp^{b+H}}, \\\\ & \\quad\\quad \\frac{e^{- (H-B)}}{1 -e^{- (H-B)}} &lt; NPV &lt; \\frac{e^{- (H+A)}}{1 -e^{- (H+A)}} \\end{aligned}\\)\nEjemplo 2.3.\nSupongamos que en un estudio caso-control, para una enfermedad con una prevalencia de 2%, el intervalo de confianza para el logaritmo de la razón de verosimilitud de diagnóstico positivo es \\(IC_{95} \\left( log(\\widehat{DLR^+}) \\right) = (1, 2.5)\\)) ¿Cuál sería el intervalo de confianza para el valor predictivo positivo?\n\\(IC_{95}(logit(\\widehat{PPV^+})) = ( log \\left( \\frac{0.02}{0.98} \\right) + 1.5, log \\left( \\frac{0.02}{0.98} \\right) + 2.5 ) = (-2.39, -1.39)\\)\n\\(IC_{95}(\\widehat{PPV^+}) = \\left( \\frac{e^{-2.39}}{1+e^{-2.39}}, \\frac{e^{-1.39}}{1+e^{-1.39}} + 2.5 \\right) = (0.08, 0.2)\\)\nEl IC indica que la prueba diagnóstica no sirve para diagnosticar la enfermedad. Dando positivo el test solo acierta la enfermedad de 0.08 a 0.2. La probabilidad de que dando positivo estemos ante un individuo enfermo es muy baja entre el 8 % y el 20 %. Otra cosa sería el NPV. No lo sabemos pero por lo menos podría ser buena para determinar que con un resultado negativo el paciente estuviera sano.\nLa prueba diagnóstica no es buena ya que solo acertaría entre un 0.08 y un 0.2 de las veces basándome en haber visto un valor positivo en la prueba. Si tomáramos esta prueba diagnóstica para hacer un diagnóstico en función del resultado los aciertos son muy pocos."
  },
  {
    "objectID": "tema_02/tema_02_1_2_cohortes_y_casos_control.html#comparación-entre-pruebas-diagnósticas",
    "href": "tema_02/tema_02_1_2_cohortes_y_casos_control.html#comparación-entre-pruebas-diagnósticas",
    "title": "1.2 Estudios de cohorte y casos-control ✓",
    "section": "Comparación entre pruebas diagnósticas",
    "text": "Comparación entre pruebas diagnósticas\nEl objetivo es comparar 2 test diagnósticos: test A y test B. Podemos comparar tres medidas (cada una de ellas enfocadas a un objetivo distinto): - Probabilidades de clasificación (cómo refleja la prueba el estado real del paciente.)\n\nValores predictivos (cómo refleja la prueba el estado real del paciente)\nRazones de verosimilitud de diagnóstico (cómo de creible es un valor postivio o negativo)\n\nEn caso de no encontrar una prueba diagnóstica “superior” a otra basándonos en las probabilidades de clasificación, podemos intentar encontrarla por medio de los valores predictivos.\nMétricas para la comparación.\n\nDiferencias absolutas (\\(\\Delta\\)) (p.e. \\(\\Delta Se(A,B) = Se(A) - Se(B))\\)\n\nOddratios (ο) (p.e. \\(οSe(A,B) = \\frac{\\frac{Se(A)}{1-Se(A)}}{\\frac{Se(B)}{1-Se(B)}} = \\frac{Se(A)·(1-Se(B))}{Se(B)·(1-Se(A))}\\)\n\nCocientes o medidas relativas (r) (p.e. \\(rSe(A,B) = \\frac{Se(A)}{Se(B)}\\))\n\nAunque se puede elegir cualquiera de ellas para comparar dos pruebas, los cocientes son más fáciles de interpretar que los odd ratios. Intenamos encontrar diferencias absolutas y en caso de no haberlas lo intentamos con los cocientes relativos.\nEn caso de tener dos pruebas diagnósticas basadas en unidades distintas, no podemos hacer difrencia de una contra la otra, pero sí puedo hacer comparaciones haciendo comparaciones entre ambas pruebas.\nProbabilidades de clasificación\nSe puede utilizar cualquiera métrica de comparación. Aunque la más utilizada es la métrica de cocientes o medidas relativas debido a su fácil interpretación.\nEjemplo:\n- \\(rSe(A;B) = \\frac{Se(A)}{Se(B)} =25\\): el test A tiene 25 veces más verdaderos positivos que el test B.\n- \\(rSe(A,B) = 0.3\\) : la cantidad de verdaderos positivos del test A es el 30 % de los observados en el test B\nValores predictivos\nLa métrica utilizada son los odds ratios o cocientes.\nSi la prevalencia de la enfermedad es baja:\n\n\\(rPPV(A,B) \\approx oPPV(A,B)\\)\n\\(rNPV(A,B) \\approx 1\\)\n\nSi la prevalencia no es baja es preferible utilizar cocientes\nEjemplo: - rPPV(A;B)=2,0Un resultado positivo en el test A es 2 veces más indicativo del riesgo de enfermedad que el que tiene un resultado positivo en el test B.\nRazones de verosimilitud de diagnóstico:\nSe comparan con la métrica de cocientes.\nExiste una relación con los odds ratios de los valores predictivo:\n\n\\(rDLR+(A,B) = oPPV(A,B)\\)\n\\(rDLR-(A,B) = \\frac{1}{oNPV(A,B)}\\)\n\nEjemplo: DLR+(A)=3,05 DLR+(B)=1,71.\n- Ambos test indican que es más verosímil un resultado positivo en enfermos que en sanos.\n- rDLR+(A,B)= 1,78. El resultado positivo del test A es más informativo del riesgo de enfermedad que el positivo del test B."
  },
  {
    "objectID": "tema_02/tema_2_28_11_2024.html",
    "href": "tema_02/tema_2_28_11_2024.html",
    "title": "tema_2_28_11_2024",
    "section": "",
    "text": "hacemos el ejercicio de la diapo54.\n\\(D = enfermo\\) \\(Y_{\\over{D}} ~ N(7.5,0.2)\\) \\(Y_{D} ~ N(8.5,0.6)\\)\n\\[\nROC(t) = \\Phi\\left( \\frac{\\mu_D - \\mu_{\\overline{D}}}{\\sigma_D} + \\frac{\\sigma_{\\overline{D}}}{\\sigma_D} \\Phi^{-1}(t) \\right)\n\\]\n\nROC &lt;- function(t, mu_D, mu_D_bar, sigma_D, sigma_D_bar) {\n  # pnorm( (mu_D - mu_D_bar) / sigma_D + (sigma_D_bar / sigma_D) * qnorm(t) )\n  pnorm( (mu_D - mu_D_bar) / sqrt(sigma_D_bar^2 + sigma_D^2) )\n}\n\n# Ejemplo de uso con valores específicos\nt &lt;- 0.5           # Valor del percentil\nmu_D &lt;- 8.5          # Media de D\nmu_D_bar &lt;- 7.5    # Media de D_bar\nsigma_D &lt;- 0.6     # Desviación estándar de D\nsigma_D_bar &lt;- 0.2 # Desviación estándar de D_bar\n\nROC_value &lt;- ROC(t, mu_D, mu_D_bar, sigma_D, sigma_D_bar)\nROC_value\n\n[1] 0.9430769\n\n\n\n#AUC = p(z&lt; (8.5-7.5) / sqrt(0.6^2 + 0.02^2) ) = (p(Z &lt; 1.58) = 0.9430\n\nes el area bajo la curva, no es una estimacion.\ncon el metodo binomal siempre que tenemos infor de algo de las respuestas d los dos grupos, no tenemos una estimacion del ara sobre la curva, sino el ara bajo la curva.\nen el momento en que tenos que usar infor adicionalo estimar valores, entonces tenemos un area estimada del ara bajo la curva.\nen este caso al ser un dato exacto no tenemos IC (que ya que lo ha preguntado una compañera lo apunto)\ninterpretación:\n\nrnorm(1, 7.5, 0.2) [1] 7.510489 rnorm(1, 8.5, 0.6) [1] 8.613545\n\nsi tengo estos dos valores y asigno el primero a un no cirro y el segundo a un sí cirrot, mi prob de acercar es 0.4.\nelijo dos valores (uno en cada muestra) y asigno el valor mas alto a los enfermo (por defecto los valores mas altos para los casos) entonces la prob de acierto es el area bajo la curva\nasí interpretaremos también al AUC estimado.\ndiapo66\nahora casos en lo que solo tenemos informacion muestral\nmuestra de resultado para casos sanos y muestra de resultados para casos enfermos.\nen la muestra correspondiente miro la proporcion de caos que están por encima del punto de corte.\nla variable respuesta es un biomarcador con unidades de medida. muchas veces la máquina correspondiente nos da pocos decimales o incluso. estamos chocando con la hipótesis de que es imposible que dos individuos tengan el mismo valor. esto lo veremos reflejado en la curva ROC, ya veremos cómo impacta.\nEjemplo.\nsupongamos que queremos estimar con el metodo empiricio la curva ROC asociada a un biomarcador y que se ha observado la siguiente muestra de resultados del biomarcador en sanos y enfermos.\n\\(Y_{\\over{D}} = (1, 1, 2, 4, 4)\\) \\(Y_{D} = (2, 3, 4, 5, 7)\\)\nLos valores observados se encuentran entre 2 y 7. Asigno c € (0.5, 7.5).\n\\(1 - \\hat{Sp}(7.5) = \\text{\"proporcion de individuos sanos que tienen valores por encima de _c_.\"} = 0\\) \\(1 - \\hat{Sp}(7.5) = \\text{\"proporcion de individuos enfermos que tienen valores por encima de _c_.\"} = 0\\)\n\nlibrary(ggplot2)\n\nY_overD &lt;- c(1, 1, 2, 4, 4)\nY_D &lt;- c(2, 3, 4, 6, 7)\n\ndf &lt;- data.frame(c=double(),\n                 `1-Sp`=double(), \n                 Se=double()) \nfor (c in seq(7.5, 0.5, by=-0.5)){\n  se &lt;- sum(Y_D &gt; c) / length(Y_D)\n  sp &lt;- 1 - (sum(Y_overD &lt; c) / length(Y_overD))\n  df &lt;- rbind(df,c(c,sp,se))\n}\ncolnames(df) &lt;- c('c', '1-Sp(c)^', 'Se(c)^')\n\nggplot(df, aes(x = `1-Sp(c)^`, y = `Se(c)^`)) +\n  geom_point(color = \"red\", size = 2) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray\", size = 1) +\n  coord_fixed(ratio = 1) +\n  scale_x_continuous(limits = c(0, 1)) +\n  scale_y_continuous(limits = c(0, 1)) +\n  labs(\n    title = \"Curva ROC\",\n    x = \"1 - Especificidad (Tasa de Falsos Positivos)\",\n    y = \"Sensibilidad (Tasa de Verdaderos Positivos)\"\n  ) +\n  theme_minimal()\n\n\n\n\neste gráfico es la estimacion de la curva roc.\n¿dónde la distancia vertical es máxima? (0, 2/5) – esto es la estiamcion del indice de youden.\na qué corresponde esa poligonal? a los empates.\nsi miras la teoria que hay detras de todo esto pues ves que esas cosas dependen de los empates.\nel AUC estimado es 0.78, sacado a mano sumando el área de los polígonos del dibujo.\n¿los valores observados están en algún sitio en la curva? nop, la curva no representa los valores. si en lugar de números hubieran sido letras ordenadas alfabéticamente hubiera sido el mismo resultado. solo es necesario saber el orden de los valores y saber si los valores se repiten. ni los valores ni el punto del corte a partir del cual decimos que eta enfermo se ve refeljado en la curva roc , a nviel global como se comporta el biomarcador pero no si discrimina o no. para ver si discrimina o no habrá que mirar el AUC, cuanto más esté a 1 mejor sirve para discriminar.\nsupongamos que c=6 es el imbral de positivos tal que si y ge6 =&gt; cuáles son las estiaciones de la sensi y la especi para c=6, sensi = 0.4 y especi = 1\nla diapo 67 es el resumen dle método empirico.\nEjemplo.\ndist gaussianas distribuciones de tipo beta. dist de tpo gamma\n\nset.seed(602)\nn &lt;- 100\nYsan3 &lt;- round(rgamma(n, 10, 3), digits=3)\nYenf3 &lt;- round(rgamma(n, 12, 3), digits=3)\nroc3 &lt;- pROC::roc(controls = Ysan3, cases = Yenf3, partial.auc = c(0,0.2))\nroc3 # pos se supone que debería dar 0.686\n\n\nCall:\nroc.default(controls = Ysan3, cases = Yenf3, partial.auc = c(0,     0.2))\n\nData: 100 controls &lt; 100 cases.\nPartial area under the curve (specificity 0.2-0): 0.197\n\n\ncambiando la semilla aka cambiando la miestra, las estimaciones de AUC cambian. aumentando el tamaño muestral obvio que tb.\ndiapo70.\n\nlibrary (pROC)\ncancer &lt;- read.csv(\"~/Master_Bioestadistica/Simulacion/tema_02/EjemploROCcancer.csv\", header=TRUE, sep=\";\")\n\nroc1 &lt;- roc(cancer$var2,cancer$var1,plot=TRUE)\n\n\n\nstr(roc1)\n\nList of 15\n $ percent           : logi FALSE\n $ sensitivities     : num [1:46] 1 1 1 1 0.967 ...\n $ specificities     : num [1:46] 0 0.0435 0.087 0.1304 0.1304 ...\n $ thresholds        : num [1:46] -Inf 0.471 0.505 0.526 0.555 ...\n $ direction         : chr \"&lt;\"\n $ cases             : num [1:30] 0.543 0.571 0.602 0.609 0.628 0.641 0.666 0.694 0.769 0.8 ...\n $ controls          : num [1:23] 0.442 0.5 0.51 0.568 0.571 0.574 0.588 0.595 0.595 0.595 ...\n $ fun.sesp          :function (thresholds, controls, cases, direction)  \n $ auc               : 'auc' num 0.809\n  ..- attr(*, \"partial.auc\")= logi FALSE\n  ..- attr(*, \"percent\")= logi FALSE\n  ..- attr(*, \"roc\")=List of 15\n  .. ..$ percent           : logi FALSE\n  .. ..$ sensitivities     : num [1:46] 1 1 1 1 0.967 ...\n  .. ..$ specificities     : num [1:46] 0 0.0435 0.087 0.1304 0.1304 ...\n  .. ..$ thresholds        : num [1:46] -Inf 0.471 0.505 0.526 0.555 ...\n  .. ..$ direction         : chr \"&lt;\"\n  .. ..$ cases             : num [1:30] 0.543 0.571 0.602 0.609 0.628 0.641 0.666 0.694 0.769 0.8 ...\n  .. ..$ controls          : num [1:23] 0.442 0.5 0.51 0.568 0.571 0.574 0.588 0.595 0.595 0.595 ...\n  .. ..$ fun.sesp          :function (thresholds, controls, cases, direction)  \n  .. ..$ auc               : 'auc' num 0.809\n  .. .. ..- attr(*, \"partial.auc\")= logi FALSE\n  .. .. ..- attr(*, \"percent\")= logi FALSE\n  .. .. ..- attr(*, \"roc\")=List of 8\n  .. .. .. ..$ percent      : logi FALSE\n  .. .. .. ..$ sensitivities: num [1:46] 1 1 1 1 0.967 ...\n  .. .. .. ..$ specificities: num [1:46] 0 0.0435 0.087 0.1304 0.1304 ...\n  .. .. .. ..$ thresholds   : num [1:46] -Inf 0.471 0.505 0.526 0.555 ...\n  .. .. .. ..$ direction    : chr \"&lt;\"\n  .. .. .. ..$ cases        : num [1:30] 0.543 0.571 0.602 0.609 0.628 0.641 0.666 0.694 0.769 0.8 ...\n  .. .. .. ..$ controls     : num [1:23] 0.442 0.5 0.51 0.568 0.571 0.574 0.588 0.595 0.595 0.595 ...\n  .. .. .. ..$ fun.sesp     :function (thresholds, controls, cases, direction)  \n  .. .. .. ..- attr(*, \"class\")= chr \"roc\"\n  .. ..$ call              : language roc.default(response = cancer$var2, predictor = cancer$var1, plot = TRUE)\n  .. ..$ original.predictor: num [1:53] 0.442 0.5 0.51 0.568 0.571 0.574 0.588 0.595 0.595 0.595 ...\n  .. ..$ original.response : int [1:53] 0 0 0 0 0 0 0 0 0 0 ...\n  .. ..$ predictor         : num [1:53] 0.442 0.5 0.51 0.568 0.571 0.574 0.588 0.595 0.595 0.595 ...\n  .. ..$ response          : int [1:53] 0 0 0 0 0 0 0 0 0 0 ...\n  .. ..$ levels            : chr [1:2] \"0\" \"1\"\n  .. ..- attr(*, \"class\")= chr \"roc\"\n $ call              : language roc.default(response = cancer$var2, predictor = cancer$var1, plot = TRUE)\n $ original.predictor: num [1:53] 0.442 0.5 0.51 0.568 0.571 0.574 0.588 0.595 0.595 0.595 ...\n $ original.response : int [1:53] 0 0 0 0 0 0 0 0 0 0 ...\n $ predictor         : num [1:53] 0.442 0.5 0.51 0.568 0.571 0.574 0.588 0.595 0.595 0.595 ...\n $ response          : int [1:53] 0 0 0 0 0 0 0 0 0 0 ...\n $ levels            : chr [1:2] \"0\" \"1\"\n - attr(*, \"class\")= chr \"roc\"\n\nYouden &lt;- roc1$sensitivities+roc1$specificities-1\nYouden &lt;- abs(Youden)\nsummary(Youden)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.1431  0.3297  0.2977  0.4453  0.5696 \n\nYI &lt;- max(Youden)\n\nplot.roc(roc1,print.auc = TRUE, legacy.axes =TRUE)\n\n\n\n\ndiapo72.\noootro ejemplo.\nno estaría mal representar histogramas y dist de densidad de los datos meustrales. nos puede dar una idea de si vamos a tener un biomarcador que nos sirva para discriminar o no.\n\nlibrary (pROC)\ncirroticos &lt;- read.csv(\"~/Master_Bioestadistica/Simulacion/tema_02/Protom_SanCirr.csv\", header=TRUE, sep=\";\")\n\n# Gráfica de las distribuciones en sanos y cirroticos\nplot(density(cirroticos$X.protombina,na.rm = T),lty=2,lwd=2,\n     xlab=\"%Protombina\",ylab=\"Densidad\",xlim=c(10,120),ylim=c(0,0.04),main=\"\",type=\"l\", col=\"darkblue\")\n\nlines(density(cirroticos$cirroticos.sanos,na.rm =T), lty=1,lwd=2, xlab=\"\", col=\"red\")\n\ntext(80,0.02, \"Sanos\", col=\"darkblue\", adj=c(1,-.1))\ntext(40,0.025, \"Cirróticos\", col=\"red\", adj=c(1,-.1))\n\n\n\n#Ref: Estimación no paramétrica de la función de densidad. Antonio Miñarro 1998\n\nparece que los sanos tienen valoers superriores a los cirroticos, y eso va al reves de nuestros default. asi que intercambaimos los valores de casos y controles.\nlos casos siempre son los que tienen mayores valores, en este caso los casos son los sanos.\nme parecia anti intiuituvo ese valor de curva roc viendo como se solapan las distribuciones pero sí que es cierto que lo que realmente se solapan son los rangos donde se distribuyen las distribuciones, pero por debajo del punto donde se cortan las distribiciones hay muy poca densidad para los sanos.\ndiapo74.\nHa dicho algo de nucleos y suavizado.\ntodo esto viene de que son variables numéricas y muestras que provienen de una variable numérica.\ndepende de algo y de un ancho de la ventana.\nen R nos deja elegir el nucleo pero no la ventana. la ventana tiene alicacion en diagnostico por imagen\ntenemos varios métodos para el suavizado. (dapi75)\nbinormal: toma una aproximacion de la densiadad a una aproximacion normal y toma las aproximaciones de una curva troc con dist binormal y considerando la muestra como una muestra proveniente de una normal con media y varianza que viene de la muestra.\ndensidad: estimar la densidad de los datos usanod un nucleo que le parezca perfecto (tal cual que ha dicho eso pero npi de qué significa su frase)\nfir-distribution: la distriubucions que mejor se aproxima a los datos por el metodo de máxoma verosiiilitud\nlognormal: …\nel AUC es la misma pq es la que estimamos usando la dist empirica. la normalizada es para dibujar solamente, sirve pq el dibujo es “mas intuitivo”, lo que hace es trazar de una forma mas “estetica” pq es una curva mas continua, y menos poligonal y escaloanda\ndiapo76.\ncómo le pongo un IC a todo esto.\nsi la muestra pequeña tan solo puedo “repetir el experimento” con muestras bootstrap (respetando el tamaño de las muestras - plural pq tengo muestra de sanos y enfermos).\nfijado punto de corte mido sensi para la pd y una especi para la pd, por lo que nuevamente puedo calcular una region de confianza.\ncon una dimension fija ver cómo variá la otra dimension. “fijada la sensi ver de qué pto a qué pto va la especi”\n[aquí ha hecho un dubujito muy boniko que a ver si lo replico.]\ndiferencia entre bootstrap y la asintotica es muy poca.\nComparación de curvas ROC\nlleva emparejado dos biomarcadores en dos muestras pareaadas o no pareadas, dependiendo del tipo de muestras usaremos un tipo de comparación y otra.\nEl estimador que se suele usar es la diferencia de las AUC, normalizado para tener una distribucion asintotica.\nSean dos pruebas diagnósticas A, B =&gt; H0: ROC_A = ROC_B\nSi las AUC son diferentes automáticamente tenemos curvas distintas (al revés no)\naparece la supervivencia ya que los sanos\nprob acumulada : densidad prob de colas : prob de supervivencia\ndiapo83\n2a.\nsi miramos las curvas (a parte de los resultados) nos gustaría saber si las consideramos la misma o no\nel p value para contrastar la hipotesis es p-value = 0.03075. si hacemos una comparacoin entre dos curvas podemos decir que no son la misma. si usamos DeLongs, el estadistico es diferente con otra dist asintotica pero decimos lo mismo. Y con Venkatraman pues eso.\nbootstrap aqui es inutil pq es mecanico y tal… no sé, que computacionalmente no tiene sentido, ¿creo?\npara esta especi de 0.9, ¿las dos pruebas me dan sensibilidades que son distintas?\ncaramba, pvalor 0.2, con lo cual las dos pruebas (partiendo de una especi de 0.9) conducen a la misma sensibilidad. y si aplico bootstrap (para hacerlo al reves, fijando sensi) me dice que no: si fijo sensi de 0.9 no admito que las dos rpeubas tenga la misma especi.\nno tengo evidencia que para una especi de 0.9 las dos sensi sean iguales\nen diapo85, para una especi de 0.9 se contrasta si la sensi_ = sensi_B. con pvalor 0.2 admito la hipóteis. no tnemos evidencias de que la sensi de ambas pruebas conese nivel de especi sea diferente.\nla segunda salida es fijo la sensi a 0.9 y contrasto si la especi de esas dos pruebas coinciden o no. con pvalor infimo puedo descartar que la especi sea igual.\nesto es un argumento de autoridad (test y un apoyo teorico que me garantiza las cosas) pero visualmente viendo las curvas ROC debemos tener unas primeras impresiones.\n“casualmete” la especi 0.9 es donde se cruzan las curvas ROC, por eso no se pueden diferencias las sensi.\npero cuando voy a mirar la seni 0.9 SÍ que hay diferencias entre as especifi\nElección del punto de corte c\nValor que hace que la pd asigne como positivo o negativo un resultado.\nsegún algún criterio.\na la hora de tener una estimacion del AUC y sobre todo su Ic nos va a dar una pista para decidir qué tipo de prueba tenemos.\nAUC – categoria &lt;0.6 – prueba caca y no merece la pensa hacer nada con ella 0.7-0.8 – buena 0.8-0.9 – buena 0.9 - 1 – excelente\nsi el AUC estimado con sus intervalos del IC es claramente menor a 0.6 la verdad es que podemos obviar esa curva ROC y no hace falta hacer ninguna comparativa con otra (alargar esta frase para resolver todos los casos pero vamos, que está entendido)\ndiapo87\nindice de youden: buscar test que tiene mayor sensi y especi\nen otro es buscar que tenga misma sensi y misma especi\nen el tercer caso queremos maximizar una de ellas\ntodas basadas en tener maxima sensi y maxima especi, dentro de lo que ofrece la prueba. si la sensi no sube de 0.6, por más que intentemos maximizarla no podremos (esto no lo entiendo, porque al final si disminuyes el pc debería poder llegar a 1)\ndiapo89. consideramos positivo si mayor a 37, pero eso no me dice nada sober la prueba. miramos el auc y es 0.74. no puedo descartar esa prueba, ya que con el IC a veces llega a ser buena.\ninterpretacion de AUC. asignando e mayor de los valores a los enfermos aciertarias estimadamente en el 74 % de las veces pudiendo variasr entre un 66 y un 62.\nacierto en una proporcion del 68 %. el ic marca 0.58 qye es muy poco pq 0.5 ya es puro azar y va hasta el 0.77 aunque muy lejos del 1. no pinta bien esta prueba eh\nla descriptiva nos hubiera ayudado mucho.\nantes estábamos mirando todo junto. ahora separamos entre muejres y hombres."
  },
  {
    "objectID": "tema_02/tema_02_3_curvas_roc.html",
    "href": "tema_02/tema_02_3_curvas_roc.html",
    "title": "3. Validación de biomarcadores. Curvas ROC ✗",
    "section": "",
    "text": "library(ggplot2)\n\ncomparacion de biomarcadores. utilidad:\n\nsobre resultados de pd donde los resultados no son positivo/negativo.\nvalidacion de biomarcadores cuando los resultados de la pd tienen varios niveles.\n\nPor convenio, se establece que los valores de la prueba en enfermos son superiores que en individuos sanos. (para los ejercicos, el by default de R, etc.)\nSe termina por dicotomizar los resultados de la pd en base a un treshold c.\nSe(c) = TPF=P(Y ≥ c/ D=1) 1-Sp(c) = FPF=P(Y ≥ c/D=0)\ncurva bidimensional doned para cualquier punto posible de la prueba calculamos pa prob de positivos en sanos y negativos en enfermos.\ndado un valor c, probabildaid de tener en los dos grupos un valor por encima de c.\nprob de tener en los enfermos un valor por encima de c y prob de tener en los sanos un valor por encima de c.\nsi c \\(\\rightarrow\\) -inf =&gt; se=1 y sp=1 si c \\(\\rightarrow\\) +inf =&gt; se=0 y sp=0\nejemplo 2.5.\nal ser distribuciones normales le pido a R la prob de tener un valor menor a c.\nej: para c=6 se(6) = prob(Y ge 6 | D=1) = 1 1-sp(6) = p(Y ge 6 | D=1) = 1\nej: para c=8.5 se(8) = prob(Y ge 6 | D=1) = 1 1-sp(8) = p(Y ge 6 | D=1) = 0.5\nnos gustaria una ROC que distinguiese perfectmenete sanos y enfermos (prueba perfecta)\numbral: punto a partir del cual asigno un positivo.\nsi es un umbral a partir del cual hago una invasiva, que sea alta si es un umbral\n\ndf &lt;- data.frame(c=double(),\n                 `1-Sp`=double(), \n                 Se=double()) \nfor (c in seq(6.5, 10.5, 0.025)){\n  sp_sincirrosis &lt;- pnorm(q = c, mean=7.5, sd=0.2, lower.tail=TRUE)\n  se_concirrosis &lt;- pnorm(q = c, mean=8.5, sd=0.6, lower.tail=FALSE)\n  df &lt;- rbind(df,c(c,1-sp_sincirrosis,se_concirrosis))\n}\ncolnames(df) &lt;- c('c', '1-Sp', 'Se')\n\nggplot(df, aes(x = `1-Sp`, y = Se)) +\n  # geom_line(color = \"blue\", size = 1) +\n  geom_point(color = \"red\", size = 1) +\n  labs(\n    title = \"Curva ROC\",\n    x = \"1 - Especificidad (Tasa de Falsos Positivos)\",\n    y = \"Sensibilidad (Tasa de Verdaderos Positivos)\"\n  ) +\n  theme_minimal()\n\n\n\n\ndiapo56\notro punto de describir la roc desde un punto de vista matemático. al dibujar la ROC el valor del umbral no aparece en la curva.\npara estudiar las propiedas de la curva roc: se varían valores de t entre [0, 1] y se trabaja con las funciones de supervivencia.\ncopiar bocadillo de la diapo.\nsi las curva de densidad de D=0 y D=1 se solapan, son iguales. es una prueba inutil\nuna prueba perfecta. aquella donde los resultados de los enfermos y la curva de los sanos son claramente diferenciables y espaciadas entre ellas.\ncuando representamos la curva roc de dos pd decir que una es mejor que la otra. si las roc no se cruzan y una está por encima de la otra e\ncurva roc nunca decrece ya que digo la proabilidad de tener el valor c o más, segun subo c pues aumenta. cuando cambiamos las propiedades de la pd mediante una transformacion creciente la ROC es la misma.\nesto es positivo cuando la transformación nos proporcione normalidad.\nmedidas para medir la calidad de ROC: AUC\neligiendo un par de resultados (uno en muestra de sanos y orto en muestra de enfermos) acertar diciendo que el sano es el que menor valor tiene en la prueba y el enfermo es el que tiene un valor mayor en la prueb tiene una prob de acierto igual a AUC\nsi una curva roc siempre está por encima de otra pos el AUC de la primera está por encima de la segunda, pero no se cumple la condición en sentido opuesto.\ndiapo60 dependiendo de dónde pongamos el ubral una prueba es más sensible que otra una de ellas solamente es preferible en algunos casos.\nel test B es mejor en el intervalo [0, 0.25]. qué tiene de bueno ese test b. la sensibilidad y la especificidad de esa prueba mejora a la otra. a partir de ese punto la interpretacion es al rev-es, la que gana en especi y seni es la A. no tengo una rpeuba que siempre supere a la otra. area bajo la curva parcial. establecer los puntos de corte en consonancia con ambas curvas.\notra medida asociada a la ROC: índice de Youden\nen algunos sitios se define como una distancia, aunque en otros sitios se define como la menor o mayor distancia.\ndistancia entre mi curva roc y la diagonal de la ROC.\npara cada punto de corte calcula la distancia con la diagonal. creo un ínidce definido como la distancia mayor.\nsi el test es perfecto, la mayor distancia es 1. si el test es inutil pues la distancia es 0.\ncuanto más se conozcca de la pd a nivel estadistico diferente será la forma de trabajar con la roc.\nconociendo como se comporta la pd, como se comparten las medidas, uso una metodologia parametrica.\nsi conozco cómo se distribuyen los resultados de la pd oues uso parametrica. la cual es idonea si hay distribucion normal en los dos grupos - sanos y no sanos -\npara normales o variables que se puedan transofrmar para ser normales pos usamos paramétricas.\nEffective with Imbalanced Datasets: In datasets where one class significantly dominates, metrics like accuracy might not provide an accurate picture. AUC, which incorporates both TPR and FPR, serves as a more reliable metric in such instances.\nlo más habitual es encontrarnos con una pd donde solo tenemos una muestra, y no tenemos informacion de la distribucion de la prueba que podamos usar en el modelo teorico.\nen el metodo empirico llegamos a tener curvas escaloanadas, lo cual queda feo ya que estamos trabajando con una variable numerica, aplicarmoe un suavizado.\ndiapo64. si conozco la distribucion de la prueba no tengo problema en calcular valores para ¿estimar? valores de sensi y especi\nsi desconocemos media o varianza pasamos a tener estimacion de la curva roc. con la muestra estimamos media y varianza de la distribucion.\nsi son normales (con test de bondad de ajuste donde no rechazo normalidad)\n(elevar potencia solo si tenemos resultados positivos como resultado de pa pd)"
  },
  {
    "objectID": "tema_02/tema_02_3_curvas_roc_final.html#determinación-de-tamaños-muestrales",
    "href": "tema_02/tema_02_3_curvas_roc_final.html#determinación-de-tamaños-muestrales",
    "title": "curvas ROC - segunda parte",
    "section": "4. Determinación de tamaños muestrales",
    "text": "4. Determinación de tamaños muestrales\nantes era fijando la anchura de un IC. tb podríamos hacerlo ahora, pero nos interesa una metodlogia que consiste en hacer un contraste de hipotesis y tener un tamaño muestra para cierta potencia dada.\nen estudios clinicos se pone en h1 la que a uno le gustaría. así cuando rechaces h0 dices “estabas protegida y mira, te he conseguido descartar”, “tengo una significatividad suficientemente grande para rechazarte”\na parte de esa confianza, los h tiene una potencia: prob de rechazar H0 cuando es falsa. queremos que sea máxima.\nObuchowski (1998) Li and Fine (2004) revisan la metodología bajo diferentes supuestos\ncualquier tipo de pd que no sea binaria, lo que hacemos con un pto de corte es hacerla binaria.\ndiapo95\ntamaños muestrales pra casos y orta para controles que garanticen niveles mínimos para la sensi y especi de la pd.\n\\(\\hat{Se} \\ge TPF_0 \\quad \\text{(1 - fraccion de falsos negativos)}\\) \\(\\hat{Sp} \\ge 1 - FPF_0 \\quad \\text{(1 - fraccion de falsos positivos)}\\)\nvalor minimo que estoy dispuesto asumir para la sensi\n“busco unos tamaños muestrales pata que la sensi de la prueba sea eta y la especi de la prueba sea esta”\nsi la especi quiero cmoom minimo este valor, entonces 1 - Sp quiero que como mucho sea 1-ese valor. cambiamos el valor minimo por una cota máxima.\n\\[H1: Se &lt; TFP_0 \\quad \\cup \\quad 1 - Sp &gt; FPF_0\\] \\[H1: Se \\ge TFP_0 \\quad \\cap \\quad 1 - Sp \\le FPF_0\\]\ndiapo95\nRegión crítica: {\\(\\text{RegCrít}_{\\alpha} = \\left\\{ FPF_{U}^{\\alpha^*} &lt; FPF_0, \\, TPF_{L}^{\\alpha^*} &gt; TPF_0 \\right\\}\\)}\nrc cuadrada y queremos una confianza de aplha, tendríamos confianza de alpha^2. de ahí sale el alpha estrella.\ndeciamos que todos los estimadores (no se cuaes) se comportaban como una binomial. vamos a trabajar con esa idea\nnumeor de enfermos y sanos se refieren a las pruebas que vamos a hacer: \\(n_D, n_{\\over{D}}\\)\nel comportamiento de estas variables se aproxima sintoticamente a una distribucion normal\n\npara conseguir casos y controles, fijados niveles minimos de se y sp tengo unos valores inciales\ncompruebo si esos valores iniciales me conducen a una potencia mayor o igual a la que quiero.\n\nuna condicion sobre la potencia de un contraste donde se supone que el valor de beta es un valor fijado por nosotros.\nmediante simulacion reproduzco marcando los valoers minimos de sensi y speci con los n_D y n_overD que he marcado antes.\ncreo dist binomial y cuento cuantas veces tengo una etimacion para esos FPF_apha\ndos valores que son los que tomamos asumiendo que la h0 es falsa. tomo dos valores dentro de la RC: \\((FPF_1, TPF_1) \\rightarrow\\) generamos muestras de tamaños \\(n_D\\) y \\(n_{\\over{D}}\\)\nsuponemos que partimos de un valor de la sensi y la especi y ahora simulamos con ese valor.\nsimulo falsos positivos con una binomial de n=casos y prob= falso positivo\nsi estoy en RC es 1, sino 0.\nasí para un n de muestras grande\npara estimar la potencia cuento cuántas muestras me han llevado a estimaciones dentro de la rc partiendo de una H0 falsa,\nsi esa potencia está por encima del requisito esos tamaños muestrales nos sirven.\nsi no, aumentamos los tamaños muestrales y volvemos a calcular.\nEjemplo 2.11.\nlo que yo quiero es: tener sensi de 0.9 y especi de 0.95\nun valor dentro de la RC. y dos valores que coforman los limites de esa RC.\n\\(H0: Se &lt; 0.75 \\cup 1 - Sp &gt; 0.2\\) \\(H0: Se \\ge 0.75 \\cap 1 - Sp \\le 0.2\\)\n\\(\\hat{Se} \\ge TPF_0 = 0.75 -&gt; TPF_1 = 0.9\\) \\(\\hat{Sp} \\ge 1 - FPF_0 = 0.2 -&gt; FPF_1 = 0.05\\)\nRegión crítica: {\\(\\text{RegCrít}_{\\alpha} = \\left\\{ FPF_{U}^{\\alpha^*} &lt; 0.2, \\, TPF_{L}^{\\alpha^*} &gt; 0.75 \\right\\}\\)}\ndetermino asitntoticamente los valores indiales para n_D y para n_overD\nhacemos al calculo de esa normal asintotica y esos valores, y los tamaños de las meustras son 64 y 46.\ngeneramos muestras de tamañaos 64 para los enfermos y 46 para los sanos.\nhacemos la matriz correspondiente y determinamos las expresiones de la diapo95 (donde sale el dibujito de la RC)\ncalculamos beta:´´voy sumando en cuántas de esas muestras los valores estumados de fL y fU está dentro de la RC\n0.87 – hay que repetir e ir incrementando. al llegar a 50 casos y x controles consigue la potencia\n70 y 50 le daban\nmuestra mas grande con misma proporcion de FP y FN.\nel primer paso es usar la dist asintotica normal para tener tañaos de partida\npuede haber más de una solucion, ya que matematicamente podemos ir aumentando de uno en uno tanto los sanos como los controles, pero tb (si estamos cerca de la potencia deseada, claro*) podemos aumentar de dos en dos sanos y de uno en uno enfermo: a criterio de cada uno, tb dependiendo de si es muy difícil encontrar sanos o enfermos, etc.\n\nsi estamos cerca de la potencia mínima deseada seguramente valga con aumentar pocas personas. si estamos muy lejos seguramente necesitemos mucha más muestra y quedaría raro si aumentamos mucho unos y muy pocos otros."
  },
  {
    "objectID": "tema_03/tema_03.html#simulación-numérica-para-desarrollar-pruebas-diagnósticas.",
    "href": "tema_03/tema_03.html#simulación-numérica-para-desarrollar-pruebas-diagnósticas.",
    "title": "TEMA 3",
    "section": "Simulación numérica para desarrollar pruebas diagnósticas.",
    "text": "Simulación numérica para desarrollar pruebas diagnósticas.\nEste es un tema instrumental. Iremos recurriendo a sus contenidos a medida que avance el desarrollo de la asignatura.\nContenidos:\n\nIntroducción (metodología y otros aspectos básicos)\nSelección aleatoria de pacientes y asignación de tratamientos\nObtención de datos simulados\nValidación de estimaciones: Metodología Bootstrap\nValidación del Índice Kappa\nTécnicas de remuestreo aplicadas a la inferencia de curvas ROC\nDeterminar el número de réplicas de simulación\nControlar la calidad de los datos simulados\nAplicaciones"
  },
  {
    "objectID": "tema_03/tema_03_1_introduccion.html#whats-simular",
    "href": "tema_03/tema_03_1_introduccion.html#whats-simular",
    "title": "1. Introducción ✓",
    "section": "What’s simular?",
    "text": "What’s simular?\nSIMULAR. Representar la realidad con un modelo.\nQueremos es una simulación estocástica \\(\\Rightarrow\\) Obtener diferentes “variedades” de una situacion donde el azar interviene. \\(\\Rightarrow\\) Lo que se conoce como estimacion de Monte Carlo.\n\nUn proceso estocástico es aquel cuyo comportamiento no es determinista, en la medida en que el subsiguiente estado del sistema se determina tanto por las acciones predecibles del proceso como por elementos aleatorios.\nUna simulación de Monte Carlo es un modelo probabilístico que puede incluir un elemento de incertidumbre o aleatoriedad en su predicción. https://aws.amazon.com/es/what-is/monte-carlo-simulation/. Técnica numérica basada en conceptos y resultados probabilísticos que consigue IMITAR un fenómeno (situación o sistema) real. Obvio que no tenemos la certeza de cuál va a ser el fenómeno, hay incertidumbre.\n\n\nLa simulación es la antítesis de los modelos teóricos en el sentido de que la simulación no duda nunca porque ya no tiene probabilidades, tiene datos. La simulación no echa cuentas, da resultados (pa’ echar cuentas ya tengo el modelo teórico).\n\nPara simular un modelo tengo que basarme en un modelo teórico. Si quiero hacer simulaciones de la realidad debo conocer el comportamiento teórico del modelo. E identificar qué partes de ese modelo depende del azar y cuáles no. Esos cambios aleatorios impactados por el azar debo definirla como una variable aleatoria.\nPor ello, no hablamos de muestras malas ni muestras buenas. Habrá simulaciones malas o simulaciones buenas.\nLos números aleatorios que nos da el ordenador en realidad son números pseudoalatorios. Dado un valor inicial se consigue el siguiente número, y a partir del segundo el tercero, etc.\nPlanteamiento de un modelo de simulación:\n\nDesarrollar un modelo que represente la situación real que se quiere investigar.\nIdentificar qué partes o fases de la situación real cambian aleatoriamente. (sexo del bebé)\nDescribir los cambios aleatorios con variables aleatorias. (Sexo: {XX, XY}, p(XX)=0.5)\nGenerar observaciones aleatorias del sistema investigado.\nValidar el modelo simulado comparando los valores simulados con las observaciones reales.\n\nLa simulación tiene dos fases:\n1. Simulación de un valor aleatorio.\n2. Dado valor aleatorio asignar el valor simulado.\nCondiciones de una simulación\n\nQue sea rápida (que la generacion de números aletorios sea rápida)\n\nLos números aleatorios generados se distribuyan entre 0-1\n\nLos números aleatorios generados se repartan por igual entre 0-1\n\nLos números aleatorios parezcan independientes\n\nLos números generados no son independientes, ya que dada una semilla siempre recreo la misma sucesión de números aleatorios. H0: necesitamos que esos números pseudoaletorios parezcan independietes (ya que sabemos que no lo son\nEjemplo\nRealizar una asignación aleatoria del sexo de un bebé. Conocido el sexo vamos a simular el peso de cada bebé.\nCriterio: dado un número aleatorio (entre 0-1) elegir el sexo del bebé. Quiero que ambos elementos tengan la misma probabilidad (divido el intervalo en dos partes iguales)\nLa base de mi modelo teorico:\nx = sexo del bebé       y = peso del bebé (kg)\n\nQuiero generar varios bebés.\n(x1, peso_1)\n(x2, peso 2)\n\nPara cada bebé tengo sexo y peso (muestras paradas pero independencia entre las observaciones).\n\np(X=varón) = 0.5 = p(x=hembra)\npeso | x=varón ~ N(3.266, 0.514)\npeso | x=hembra ~ N(3.155, 0.495)\n\n\nGenero un número aleatorio.\nHago una simulación.\nSaco los datos simulados.\nReciclo semilla.\n\n\n\n\n\nTengo dos variables que simular.\n- Un número aleatorio para simular la primera variable.\n- Otra variable que no conozco pero que está condicionada. Otro número para simular para la otra variable.\n\nn=6; set.seed(20175)\n\nU=runif(n,min=0,max=1)\np=0.5;\npeso=numeric(n);\nsexo=character(n);\n\nfor(i in 1:n) {\n  if (U[i]&lt;p){\n    pp=rnorm(1,3.266,0.514)\n    peso[i]=pp\n    sexo[i]=\"varon\"\n } else {\n   pp=rnorm(1,3.155, 0.495)\n   peso[i]=pp\n   sexo[i]=\"mujer\"\n }\n}\n\n\ncat(\"Números aleatorios:\", U, \"\\n\")\n\nNúmeros aleatorios: 0.7621414 0.3668522 0.3111475 0.6270264 0.07654514 0.7816305 \n\ncat(\"Sexo:\", sexo, \"\\n\")\n\nSexo: mujer varon varon mujer varon mujer \n\ncat(\"Peso:\", peso, \"\\n\")\n\nPeso: 3.913199 3.536088 2.989453 3.101755 2.76329 3.636893 \n\n\n\nn=100000; set.seed(20175)\nU=runif(n,min=0,max=1)\np=0.5;\npeso=numeric(n);\nsexo=character(n);\n\nfor(i in 1:n) {\n  if (U[i]&lt;p){\n    pp=rnorm(1,3.266,0.514)\n    peso[i]=pp\n    sexo[i]=\"varon\"\n } else {\n   pp=rnorm(1,3.155, 0.495)\n   peso[i]=pp\n   sexo[i]=\"mujer\"\n }\n}\n\n# Histograma muestral n=100000\nhist(peso,freq=FALSE)\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nComo tengo dos muestras, dos variables, necesito que la creación de la simulación de cada una de las variables sea independiente. Necesito que la semilla de cada variable aleatoria, AKA la semilla de cada variable simulada, sea diferente. Al ser números pseudoaleatorios estaría condicionada la primera y segunda variable simulada.\n(esto no tiene nada que ver con que una variable esté condicionada a la otra)\n\n\n\n\n\n\n\n\nAcerca del ejercicio que nos mandó\n\n\n\nPuedo simular un número aleatorio para un hijo y luego otro para el segundo hijo. O un método para simular con un único número aleatorio los dos hijos a la vez (vamos, crear todas las condiciones con un único número aleatorio).\n\n\nMuy bien mijo, ¿pero y si tengo que simular algunas de las distribuciones no conocidas?\nExisten métodos generales para ello. Si tengo que simular distribución conocida estoy ok. Si tengo que generar una variable desconocida entonces tendré que crearla por distintos métodos.\n\n\n\n\nLa pregunta es, ¿qué nrum le pongo?"
  },
  {
    "objectID": "tema_03/tema_03_2_selección_aleatoria.html",
    "href": "tema_03/tema_03_2_selección_aleatoria.html",
    "title": "2. Selección aleatoria de pacientes y asignación de tratamientos ✗",
    "section": "",
    "text": "Advertencia\n\n\n\nQuedan por incluir unos ejemplos por algún lado del tema 3.\n\n\nObjetivo.\nLlegar a una conclusión que sea válida. Valido = representativo.\nAleatorización.\nExigencia teórica impuesta a experimentos y ensayos clínicos con el objetivo de minimizar la variabilidad de las evaluaciones y evitar la distorsión que pueden producir otros factores en las pruebas experimentales.\nCuántas veces debería hacer la simulación para saber que el resultado es verdaderamente cercano al valor desconocido real. La validez de una estimación está ligada al conportamiento de lo que quiero estimar y con la cantidad de información que tenga.\nHipótesis.\n\nLos pacientes se eligen aleatoriamente. Cualquier grupo de n pacientes tiene las mismas posibilidades de ser elegido.\n\nEl tratamiento es asignado aleatoriamente. No hay preferencias en la asignación, cada paciente tiene las mismas oportunidades de recibir uno de los tratamientos.\n\nDebo de partir con la idea de que todas las personas que son similares.\nSi quiero hacer una comparacion voy a procurar que el tamaño entre las personas que reciben cada uno de los tratamientos es similar.\nEjemplo: aplico varias metodologías de aprendizaje en niños, no puedo tener 10k niños con la metodología antigua y 1 unidad de niños con la metodología nueva, aunque todos sabemos que luego esto nunca se lleva a cabo correctamente. (vamos, la diapo14)\nObjetivos de la aleatorización.\n\nAsegurar que cualquier paciente tiene las mismas oportunidades de recibir el tratamiento experimental.\n\nEliminar sesgos en la selección.\n\nEquilibrar el tamaño de los grupos. (en función del objetivo o de las características experimentales)\n\nVerificar o estudiar la eficacia de los tratamientos.\n\nRazones para la aleatorización.\n\nLos sujetos asignados a cada tratamiento tendrán características similares.\n\nSin similitud =&gt; Sesgo en los resultados.\n\n\n\nNi el investigador, ni el paciente tendrán conocimiento del grupo de asignación en el que se va incluir al participante en el estudio.\n\nSesgo en la selección =&gt; Efectos del tratamiento sobredimensionados.\n\n\n\nLa aleatorización garantiza la validez de los test estadísticos utilizados para comparar tratamientos.\n\nLa aleatorización estratificada y la aleatorización adaptada a las covariables controlan la influencia de las covariables.\nSi quiero ver si un medicamento funciona mejor que otro:\n\nNecestiamos trabajar sobre un modelo matematico que me confirme que los individuos no estén relacionados entre sí (si son familia pues les sentará igual de mal o igual de bien cada uno de los tratamietos) y homogeneidad entre los dos grupos (un grupo más sano que otro)\nSi quiero asginar mi muestra en dos grupos la asignación aleatoria de cada individuo uno por uno va mal si tenemos una muestra reducida (elijo una persona y la asigno aleatoriamente a un grupo, luego con la siguiente). Si n es grande a la larga tendré estabilidad de frecuencias.\n\nAleatorización simple\nEstá basada en una única serie de asignaciones aleatorias. Los pacientes se asignan a los grupos de tratamiento del estudio clínico.\nSe puede imponer un control realizando asignaciones de modo que haya el mismo número de individuos en cada grupo.\nDe un grupo de individuo cojo n de ellos sin que se repitan.\n\nset.seed(178900)\ntrat=sample(1:20,10,replace=FALSE)\nindiv=sort(trat)\nindiv\n\n [1]  2  3  4  6  9 10 11 13 17 18\n\n\nSi tengo un n muy grande participando en el estudio no tengo que preocuparme por la selección.\nVentajas:\n\nEs un procedimiento sencillo y fácil de poner en práctica.\n\nEn estudios de muchos pacientes la aleatorización simple conduce a grupos con un número similar de participantes.\n\nDesventajas:\n\nLos resultados de la aleatorización pueden dar lugar a grupos de tamaños muy desiguales cuando el estudio involucra a un número reducido de pacientes.\n\nProblema:\n\nA veces no tengo todos mis pacientes a mis disposición, por ejemplo, a mitad del estudio este se para y tenemos x individuos sin haberle podido dar el tratamiento (ej: se rompe la máquina que da la dosis y muchos pacientes se quedan sin dosis)\n\nSi el suceso de no poder realizar la asignación a todos los individuos es altamente probable debo tenerlo contemplado. Para ello usamos la aleatorización por bloques.\nPor bloques o restringida\nPermite asignar aleatoriamente sujetos en los grupos de tratamiento de igual tamaño dividiendo a los pacientes potenciales en m bloques de tamaño 2n, n&gt;1.\nEn lugar de colocar las n personas al mogollón, voy equilibrando grupos más pequeños. Así si se interrumpe el experimento tengo un experimento más pequeño pero bien repartido.\nEl procedimiento consiste en repartir toda la muestra en x aleternativas igual que antes pero en vez de tener n/2 y m/2, fijo un tamaño del bloque y dentro de cada bloque jeugo con un reparto equitativo.\nEl procedimiento se basa en la construcción de todos los posibles bloques distintos formados con n asignaciones A (tratamiento) y n asignaciones B (placebo). La elección de cada bloque es aleatoria.\nSelección del tamaño de los bloques.\n\nTamaño n múltiplo del número de tratamientos.\n\nTamaño n no muy grande porque precisamente lo que quiero son bloques no grandes para poder tener la asignación equilibrada.\n\nEl n=6 suele ir bien.\n\nTamaño n dividendo del total de la muestra parece no ser una condición, tal vez el último bloque sea de menor tamaño para asignar a los individuos sin tratamiento.\n\nVentajas:\n\nEl método asegura tener grupos de tamaño equilibrado a lo largo del proceso de asignación, siempre que se use el bloque completo.\n\nDesventajas:\n\nHay que ocultar el tamaño del bloque al clínico para que la asignación no sea predecible.\n\nSi el experimento es doble ciego quiero que el médico no sepa que es asignación por blqoues, ya que si estoy asignando el primer bloque y la mitad de los individuos tienen un tratamiento automáticamente sabe que los n siguientes individuos van a tener el otro tratamiento.\nEjemplo\nAsignar tratamiento o placebo a 60 sujetos utilizando bloques de tamaño 6 (2n=6).\nCreo todos los bloques de asignación posible con todos los órdenes de asignación.\n\n\n\n\nSelecciono con reemplazamiento los bloques necesarios.\n\nset.seed(32581)\nsample(1:20,10,replace=TRUE)\n\n [1]  7  4 15  5 19  3  5  2 12 19\n\n\nEstratificada\nSe utiliza para conseguir un equilibrio entre los grupos respecto a otras características (covariables) de los sujetos. Se complica con la cantidad de covariables que quiera incluir para la creación de grupos.\nControla la posible influencia de las covariables en las conclusiones de la investigación.\nLa asignación uno a uno de los individuos no se puede si quiere controlar las covariables. La asignación estratificada debe hacerse de entrada. Necesito conocer qué niveles tengo para cada covariable y definir el tamaño muestral para cada nivel o combinación de niveles.\nEl número de estratos es el múltiplo del número de niveles de cada covariable.\nEn cada estrato se genera una secuencia de asignación mediante aleatorización simple o por bloques.\nVentajas:\n\nEl método asegura tener grupos de tamaño equilibrado teniendo en cuenta los factores influyentes.\n\nDesventajas:\n\nPrecisa conocer todas las características de los sujetos con anterioridad a la asignación en grupos.\n\nLa técnica se complica al aumentar el número de covariables.\n\nNo puede utilizarse si los sujetos se incluyen en el estudio uno a uno.\nAdaptativa o minimización\nTenemos un equilibrio en los bloques en función de los individuos que vamos recibiendo.\nSe utiliza para minimizar las diferencias de los tamaños de los distintos grupos.\nCada nuevo sujeto se asigna secuencialmente a un grupo concreto de tratamiento teniendo en cuenta las covariables y las asignaciones de los sujetos anteriores.\nEl investigador debe elaborar un plan de aleatorización para asignar los tratamientos a los pacientes\nVentajas:\n\nEl método es útil cuando hay muchas covariables y si la muestra de sujetos es pequeña.\n\nDesventajas:\n\nPrecisa recoger todas las características de los participantes con anterioridad a la aleatorización."
  },
  {
    "objectID": "tema_03/tema_03_3_obtener_datos_simulados.html#simulación-paramétrica",
    "href": "tema_03/tema_03_3_obtener_datos_simulados.html#simulación-paramétrica",
    "title": "3. Obtener datos simulados a partir de observaciones reales ✓",
    "section": "Simulación paramétrica",
    "text": "Simulación paramétrica\nEl peor de mis problemas es tener poca muestra ya que me complica cómo validar mis estimaciones.\nA partir de los datos observados (\\(y_1, …, y_n\\)) calculamos el valor del estimador del parámetro del modelo paramétrico, \\(\\hat{\\theta}\\).\n\n\\(\\theta\\) es el verdadero valor del parámetro poblacional.\n\\(\\hat{\\theta}\\) es el estimador que se calcula a partir de los datos muestrales.\n\\(\\hat{\\theta*}\\) es una estimación del mismo parámetro obtenida mediante una técnica de remuestreo, usada para analizar la variabilidad del estimador \\(\\hat{\\theta}\\)\n\nEjemplo\n\\[\n\\theta = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} |z_1 + z_2| e^{-\\frac{z_1^2 + z_2^2}{2}} \\, dz_1 dz_2\n\\]\n\\[\n\\theta = E \\left[ 2\\pi |Z_1 + Z_2| \\right], \\text{ siendo } Z_1 \\text{ y } Z_2 \\text{ v.a. } N(0,1) \\text{ independientes}\n\\]\n\nNsim=10000\nset.seed(5597)\n\nZ1 &lt;- rnorm(Nsim)\nZ2 &lt;- rnorm(Nsim)\nX &lt;- 2*pi*abs(Z1+Z2)\n\nesperanza_X &lt;- mean(X)\nsd_X &lt;- sd(X)\n\nalpha &lt;- 0.05\nz_a2 &lt;- qnorm(1-(alpha/2))\n\nLower &lt;- esperanza_X - (z_a2*sd_X/sqrt(Nsim))\nUpper &lt;- esperanza_X + (z_a2*sd_X/sqrt(Nsim))\nc(Lower, esperanza_X, Upper)\n\n[1] 7.024079 7.129826 7.235572\n\n\nValidez de la estimación\nSe generan nuevas muestras (\\(y*_1, …, y*_n\\)) a partir de la distribución \\(F(\\hat{\\theta})\\).\n\nObjetivo de la simulación.\nConseguir información sobre la distribución del estimador T de interés.\nSi existen resultados teóricos para la distribución de T o la relación entre el estimador y su parámetro es preferible utilizarlos a depender del resultado de la simulación.\n\n¿Cómo procedemos si tenemos problemas?.\nPosibles problemas:\n\nLas propiedades teóricas de T son complicadas.\n\nNo hay resultados asintóticos.\n\nLa muestra observada es pequeña.\n\n\nTécnicas Bootstrap [Man] (remuestreo con reemplazamiento)\n\nTécnica Bootstrap\nCuando no tenemos información de la población, la distribución empírica de una muestra aleatoria es la mejor representación de la distribución de la población ==&gt; La muestra observada se toma como modelo de la distribución desconocida.\nSi hay un resultado teorico, al teorico. Si hay una aproximación, a la apriximación. Si no hay información suficientepara tirar por lo asintótico (asintótico AKA apoximación) y tengo poca muestra: Bootstrap.\nPara mejorar el conocimiento de la distribución real la técnica bootstrap realiza muestreos con reemplazamiento teniendo en cuenta la distribución empírica.\n\nSi las características del estimador no son conocidas o son muy complejas o tengo muestra muy pequeña, uso Bootstrap. Bootstrap no crea ni destruye nada.\n\nRemuestreo. Saco muestras del mismo tamaño que la inicia. “Mi muestra era esta, pero si tomara nuevas muestras del mismo tamaño mi población sería esta”.\nFinalidad.\n- Validar, mediante intervalos de confianza, la estimación del parámetro que se consigue a partir de la muestra observada.\n- Realizar contrastes de hipótesis.\nProcedimiento.\n\nSean \\((y_1, …, y_n)\\) los resultados de una medida X en n sujetos independientes.\n\nSea \\(\\theta\\) una cantidad referida a X (valor medio, mediana, desviación…).\n\nCon los resultados observados podemos calcular el valor estimación de \\(\\theta\\): \\(\\hat{\\theta}\\)\n\n\nValidación de la estimación por IC.\n\nSimulamos una nueva muestra (\\(y*_1, …, y*_n\\)) remuestreando con repetición en los resultados iniciales y calculamos el valor de \\(\\hat{\\theta*}\\).\n\nRepetimos el proceso r-veces obteniendo r estimaciones bootstrap: \\(\\hat{\\theta_i*}\\), i=1,2,…r.\n\n¿Cuántas muestras? Eso es el capítulo final del tema.\n\n\nCalculamos las diferencias entre las estimaciones bootstrap y la estimación conseguida con la muestra inicial: \\(d_i = \\hat{\\theta_i*} - \\hat{\\theta}\\).\n\nObtenemos los cuantiles asociados \\(\\alpha/2\\) y \\(1-\\alpha/2\\): \\(d_b\\), \\(d_u\\).\n\nEl intervalo de confianza bootstrap \\(1-\\alpha\\) es: \\([\\hat{\\theta} + d_b, \\hat{\\theta} + d_u]\\)\n\n\nLa muestra original la guardo y la dejo apartada y trabajo con las muestras de Bootstrap (bueno esto volver a preguntárselo de cara a algún ejercicio pq tampoco creo si me ha contestado lo mismo dos veces seguidas). Trabajamos solo con las r estimaciones Bootstrap."
  },
  {
    "objectID": "tema_03/tema_03_3_obtener_datos_simulados.html#simulación-no-paramétrica",
    "href": "tema_03/tema_03_3_obtener_datos_simulados.html#simulación-no-paramétrica",
    "title": "3. Obtener datos simulados a partir de observaciones reales ✓",
    "section": "Simulación no paramétrica",
    "text": "Simulación no paramétrica\nNo se asume una distribución teórica, se remuestrea los datos originales para simular nuevas muestras.\ndiapo43 es la distribución del estadístico\npero no es la distribucion de p, sino del estadñistico\ncon la simulacion ya no tengo estimaciones, tengo estimaciones de la probabilidades\nlas muestras no tienen probabilidad, pq las muestras están fijas. tienen frecuencias, no dudo. en el modelo teórico tengo algo genérico, ahí sí hablo de probabilidades"
  },
  {
    "objectID": "tema_03/tema_03_3_obtener_datos_simulados.html#ejemplo-validar-índice-kappa",
    "href": "tema_03/tema_03_3_obtener_datos_simulados.html#ejemplo-validar-índice-kappa",
    "title": "3. Obtener datos simulados a partir de observaciones reales ✓",
    "section": "Ejemplo: Validar índice Kappa",
    "text": "Ejemplo: Validar índice Kappa\nSupongamos que se examinan 20 radiografías de la columna con el fin de detectar daños en la misma. Un par de radiólogos examinan las placas y emiten su diagnóstico: N = sin daño, I = daño incipiente, S = daño severo.\n\\[\n\\begin{array}{cc|ccc}\n& & \\textbf{Radiólogo A} \\\\\n& & \\textbf{N} & \\textbf{I} & \\textbf{S} \\\\\n\\hline\n\\textbf{Radiólogo B} & \\textbf{N} & 6 & 1 & 0 \\\\\n                      & \\textbf{I} & 1 & 3 & 2 \\\\\n                      & \\textbf{S} & 0 & 3 & 4 \\\\\n\\hline\n& & & & & 20 \\\\\n\\end{array}\n\\]\n\\(\\hat\\kappa_0\\): estimacion con la muestra inicial\nn=20 \\(\\Rightarrow\\) Validacion con la metodlogía bootstrap. - Remuestreo entre las 20 diapos, cada diapo tiene 2 clasificaciones - Para cada muestra tengo una estimación de \\(\\hat\\kappa_{b_{1}}\\). - Haste tener \\(\\hat\\kappa_{b_{1000}}\\), tendré mil valores de mis estimaciones\n\n# 0 = sin lesion, 1 = daño leve, 2 = daño severo\nlibrary(psych)\nrad1 &lt;- c(2,1,0,0,2,0,0,0,2,2,1,1,2,0,1,1,2,2,1,0)\nrad2 &lt;- c(1,1,0,0,2,0,0,0,2,2,1,2,1,1,1,0,2,1,2,0)\n\n\ncokapp &lt;- cohen.kappa(x&lt;-cbind(rad1,rad2))\n#str(cokapp)\ncokapp$kappa\n\n[1] 0.4756554\n\nCoefi &lt;- cokapp$kappa\n\nBootstrap para Kappa\n\n#estructura bootstrap\nN_boot &lt;- 2000\nnn &lt;- length(rad1)\nB1 &lt;- numeric(nn)\nB2 &lt;- numeric(nn)\nk_boo &lt;- N_boot\n\n\n#Remuestreo en las placas de radiografías\nset.seed(108)\ntmp1 &lt;- sample(1:nn, nn*N_boot, replace=TRUE)\n\n\n# Asignamos a cada valor tmp1 la opinion de los radiologos\n# B1 para el radiólogo 1 y B2 para el radiólogo 2\n# Calculamos kappa en cada muestra bootstrap\n\nfor(j in 1:N_boot){\n  jj &lt;- j-1\n  for( i in 1:nn){\n    B1[i] &lt;- rad1[tmp1[nn*jj+i]]\n    B2[i] &lt;- rad2[tmp1[nn*jj+i]] }\n  y &lt;- cbind(B1,B2)\n  ckb &lt;- cohen.kappa(y)\n  k_boo[j] &lt;- ckb$kappa\n}\n\ndiff &lt;- k_boo - cokapp$kappa\ncuantiles &lt;- quantile(diff, c(.05, .95))\n(IC_kappa &lt;- cokapp$kappa + c(cuantiles[1], cuantiles[2]))\n\n       5%       95% \n0.1821561 0.7014925 \n\n\nVamos a analizar las diferencias entre la estimacion de la muestra inicial m0 contra cada una de estas estimaciones:\n\nConcordancia desde insignificante hasta sustancial.\nMuy muy muy válida la estimación no es.\n\nNo es porque la hayamos hecho mal, sino porque no podemos defender a muerte nuesta estimacion puntual.\nLo que sí podemos decir es que algún criterio común tienen."
  },
  {
    "objectID": "tema_03/tema_03_4_remuestreo_inferencia_roc.html#remuestreo-bootstrap-naïf",
    "href": "tema_03/tema_03_4_remuestreo_inferencia_roc.html#remuestreo-bootstrap-naïf",
    "title": "4. Técnicas de remuestreo aplicadas a la inferencia de curvas ROC ✗",
    "section": "Remuestreo bootstrap Naïf",
    "text": "Remuestreo bootstrap Naïf\nGenera una muestra con reemplazamiento de \\(n\\) individuos con información \\((Y_i, D_i)\\) de mi muestra.\nPor lo general conduce a malas aproximaciones de los cuantiles de la distribución empírica.\nAl elegir aleatoriamente con reemplazamiento pierdo la proporción de enfermos y sanos.\nPara generar la curva ROC y demás estimaciones perdemos la characteristic intrínseca del biomarcador de que no haya valores repetidos.\n\nRemuestreo bootstrap con aproximación de Monte-Carlo\nTras obtener un remuestreo naïf se altera el resultado de la prueba. Se perturba a través de la simulación de un valor aditivo \\(a\\) con distribucion \\(N(0, \\frac{1}{\\sqrt[5]{n}})\\)\nConseguimos alterar levemente los resultados del remuestreo naïf para romper esos “empates”.\nReproduce las ventajas teóricas del procedimiento suavizado con núcleo Gaussiano.\n\\[\n\\begin{array}{|c|c|}\n\\hline\n\\textbf{Y} & \\textbf{D} \\\\ \\hline\n\\hline\nY_1 + a_1 & D_1 \\\\ \\hline\nY_2 + a_2 & D_2 \\\\ \\hline\n\\vdots & \\vdots \\\\ \\hline\nY_n + a_n & D_n \\\\ \\hline\n\\end{array}\n\\]\n\n\nBootstrap suavizado con núcleo K\ntrabajar priemero con las funciones de distribucion empricas y simular con ellas\n\ntener muestra inicial\n1.1. aplicarmétodos asintóticos y pensar que es caca\n\nestimar curva roc y AUC\n2.1 esos valoers originales serán ROC_0 y AUC_0\n\nremuestreo a partir de la muestra inicial con la pertubación añadida del mismo tamaño muestral\n\nsaco la curva ROC y AUC\n\nRepito el punto 3 y 4.\n\nB muestras\nsi el “Calculamos di= AUC*i – AUC^, i=1,…,B” lo hiciéramos sin hacer la resta, es decir, apartar solo los extremos de las muestras en vez de los extremos de las diferencias, podría pasar que mi estimacion inicial no estuviera en el intervalo.\nel hacer la resta y tal se hace para asegurar que mi estimacion está contenida en el intervalo. busco la estimacion del AUC de las muestas bootstrap\nNOTA: en la diapo51 los \\(\\hat{F}_D^*\\) y \\(\\hat{F}_{\\over{D}}^*\\) son estimados.\nEjemplo.\nlos pacientes sin anemia tiene unos contenidos de hierro bajo inferiores (relacion inversa a la que estamos acostumrbados): tengo que identificar los ceros y los unos al revés.\nseleccionamos remuestreos, alterarlo con la dist normal, calcular diferencias, etc.\nes es curva roc con muestra inicial. 0.70 puede ser una pruebaadmisible si tuvieramos un IC que dice que no estamos con algo muy disparatado.\ncalculamos el IC. para una muestr que no era muy grande y aplicamos boots pq no etabamos seguros que nos diera buenos resultados aplicando los metodos asintoticos nos un IC estrechito. buscamos punto de corte con el metodo habitial.\n¿el índice yeuden (pregunto yo) es sobre la muestra original o sobre las muestas simuladas?\nyouden lo haces sobre tu original, la simu bootrap lo utilizas para IC para tu curva roc.\n\nbandas para la roc\ndiapo55 compara las curvas bootstrap de las muestras simuladas y la original. busca la máxima distancia entre las curvas simuladas y la original.\ntomar una dist mayor entre las muestra roc original y las roc simualadas por boostap"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Camargo-Ramos, C. M., and otros autores. 2012. “Evaluación de\nFactores Asociados Al Embarazo Adolescente.” Revista\nColombiana de Obstetricia y Ginecología 61 (3): 256–62. http://www.scielo.org.co/pdf/rcog/v61n3/v61n3a09.pdf.\n\n\nFisterra. 2024. “La Fiabilidad de Las Mediciones Clínicas:\nAnálisis de La Concordancia Para Variables Numéricas.” 2024. https://www.fisterra.com/formacion/metodologia-investigacion/la-fiabilidad-mediciones-clinicas-analisis-concordancia-para-variables-numericas/."
  }
]